%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% This report has been adapted from the following template:
% The Legrand Orange Book
% LaTeX Template
% Version 2.4 (26/09/2018)
%
% This template was downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Mathias Legrand (legrand.mathias@gmail.com) with modifications by:
% Vel (vel@latextemplates.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
% Some changes made to the template:
% We use natbib for citations, and this significantly changes the Bibliography page
% We also change the colors and images used in the chapter headers and so on.
%
%
% This template also uses a number of packages which may need to be
% updated to the newest versions for the template to compile. It is strongly
% recommended you update your LaTeX distribution if you have any
% compilation errors.
%
% Important note:
% Chapter heading images should have a 2:1 width:height ratio,
% e.g. 920px width and 460px height.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[11pt]{book} % Default font size
\usepackage{blindtext}
\usepackage{lipsum}
\usepackage{textcomp}
\usepackage{gensymb}
\usepackage{pdfpages}
\usepackage{mathtools}
% \usepackage{subfigure}
\usepackage{titling}
\usepackage{authblk}
\usepackage{eso-pic}
\usepackage[nottoc]{tocbibind}
\usepackage{natbib}
\usepackage{aas_macros}
\usepackage[outputdir=cache]{minted}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{graphics}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{units}
\usepackage[utf8]{inputenc}
\usepackage{subcaption}
\usepackage[export]{adjustbox}
\usepackage{url}
\usepackage{hyperref}
\usepackage{xcolor}
% \usepackage{wasysym}
% \usepackage{marvosym}
% \usepackage{gensymb}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily,
    \lst@ifdisplaystyle\scriptsize\fi,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}

%% THEME
\input{structure.tex} % Insert the commands.tex file which contains the majority of the structure behind the template

\definecolor{theme}{RGB}{76,139,245} % Redefine the color used for highlighting throughout the book. 

\renewcommand{\familydefault}{\sfdefault}

%\hypersetup{pdftitle={Title},pdfauthor={Author}} % Uncomment and fill out to include PDF metadata for the author and title of the book

%----------------------------------------------------------------------------------------

%% TITLE 
\title{\color{white}
	{\LARGE\sffamily\textsc{\color{black}Krittika Summer Projects 2023}}\\
	\normalfont\fontsize{35}{35}\selectfont
	\textbf{\color{black} Faintest of the Brightest}}

%% AUTHORS and AFFILIATIONS
\author[1,2]{\color{black}Ravi Kumar}
\author[1,2,3]{\color{black}Gaurav Waratkar}
\author[2,3]{\color{black}Meghna Dixit}


\setlength{\affilsep}{3em}
% Check your affiliations
\affil[1]{\protect\raggedright\normalfont\fontsize{10}{0}\selectfont Krittika - The Astronomy Club of IIT Bombay, Powai, Mumbai - 400076, India}
\affil[2]{Indian Institute of Technology Bombay, Mumbai - 400076, India}
\affil[3]{Mentor for the Project}


\date{}


\begin{document}
\makeatletter
\newcommand{\printauthorlist}{
    \begin{center}
		\expandafter\let\csname textsuperscript \endcsname\@gobble % Remove \textsuperscript 
		\AB@authlist% Print list
	\end{center}
}
\makeatother

%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------

\begin{titlepage}
	\begingroup
	\thispagestyle{empty}
        \begin{center}
	\AddToShipoutPicture*{\includegraphics[height=\paperheight, width=\paperwidth]{Pictures/cover.png}}
        \end{center}
	\vspace*{25em}
	{\centering
	\makeatletter
		\@title\\[0.5em]
		{\normalfont\LARGE\printauthorlist}
	\makeatother
	}
	\endgroup

\end{titlepage}

%----------------------------------------------------------------------------------------
%	COPYRIGHT/ALT TITLE PAGE
%----------------------------------------------------------------------------------------

\begin{titlepage}
	\thispagestyle{empty}
	\date{\protect\raggedright
		\vfill
		\noindent Copyright \copyright\ 2023 Krittika IITB\\ %Copyright notice
		\noindent \textsc{Published by Krittika: The Astronomy Club of IIT Bombay}\\ % Publisher	
	First Release, July 2023 % Printing/edition date
}
	\maketitle
\end{titlepage}

%----------------------------------------------------------------------------------------
%	ABSTRACT
%----------------------------------------------------------------------------------------

\newpage
\pagestyle{empty}
\begin{center}
{\huge \textmd{Abstract}}\\
\par
\vspace{20pt}
Gamma-ray bursts (GRBs) are fascinating astronomical phenomena that have captured the attention of scientists and researchers around the world. These powerful bursts of gamma-ray radiation, lasting from a fraction of a second to a few minutes, provide valuable insights into the universe's workings.
\newline

To understand GRBs and their origins, astronomers employ various methods of analysis. In this paper, we will focus on how to analyze data from the Cadmium Zinc Telluride Imager (CZTI) onboard ISRO's famous AstroSat, currently in orbit.
\newline

We process the CZTI data using \textit{cztpipeline}, which automatically runs a series of processing modules to yield clean, user-friendly data files. A section in this paper explains the working of the CZTI Pipeline and gives a bird's eye view into building a GUI data processing platform.
\newline

Ultimately, we will implement various signal processing concepts on the CZTI data, to mathematically determine the location and significance of the GRB.

\end{center}
\vspace{5em}


%----------------------------------------------------------------------------------------
%	TABLE OF CONTENTS
%----------------------------------------------------------------------------------------

% \usechapterimagefalse % If you don't want to include a chapter image, use this to toggle images off - it can be enabled later with \usechapterimagetrue

\chapterimage{index} % Table of contents heading image

\pagestyle{empty} % Disable headers and footers for the following pages
%\setcounter{tocdepth}{0}
\tableofcontents % Print the table of contents itself

\pagestyle{fancy} % Enable headers and footers again

%----------------------------------------------------------------------------------------
%	CHAPTER 1
%----------------------------------------------------------------------------------------

\chapterimage{astrosat} % Chapter heading image

\chapter{Introduction}
\section{Gamma Ray Bursts}
\subsection{What are Gamma Ray Bursts?}
Gamma-ray bursts (GRBs) are massively large explosions caused when a star dies resulting in a supernova, when two \href{https://en.wikipedia.org/wiki/Neutron_star}{neutron stars} collide, or when a neutron star collides with a \href{https://en.wikipedia.org/wiki/Black_hole}{black hole}, releasing a large amount of energy.  

\begin{figure}[H]
\centering
    \includegraphics[width=0.7\textwidth]{Pictures/grb_shell_final_0.jpg}
    \caption{Emissions of a GRB (Source: \href{https://www.nasa.gov/feature/goddard/2023/nasa-missions-study-what-may-be-a-1-in-10000-year-Gamma-ray-burst}{NASA's Goddard Space Flight Center})}
\end{figure}

This illustration shows the ingredients of a long Gamma-ray burst, the most common type. The core of a massive star (left) has collapsed, forming a black hole that sends a jet of particles moving through the collapsing star and out into space at nearly the speed of light. Radiation across the spectrum arises from hot ionized gas (plasma) in the vicinity of the newborn black hole, collisions among shells of fast-moving gas within the jet (internal shock waves), and from the leading edge of the jet as it sweeps up and interacts with its surroundings (external shock). The presence of a prompt emission and a much longer afterglow (in multiple wavelengths) is a common feature of GRBs.

\subsection{Classification of GRBs}
GRBs are classified into 3 main classes, short, long and ultra-long, according to the duration for which they are detected.

\begin{wrapfigure}[15]{r}{0.4\textwidth}
    \includegraphics[width=0.4\textwidth]{Pictures/neutronstars.jpg}
    \caption{Artist depiction of a GRB created by two merging neutron stars (Source: \href{http://www.markgarlick.com/index.html}{Mark A. Garlick})}
\end{wrapfigure}

\textbf{Short GRBs} are events with a duration of less than 2 seconds, and the Gamma rays from short bursts lean toward the high-energy end of the spectrum, while long GRBs emit lower-energy Gamma rays. They are thought to be caused by the merger of two neutron stars or a neutron star and a black hole and account for about 30\% of detected GRBs.


\textbf{Long GRBs} are events with a duration of more than 2 seconds. Although the Gamma rays emitted are of lower energy than short GRBs, the total energy output of long GRBs is generally higher owing to their longer duration. They are thought to be caused by the core collapse of rapidly rotating massive stars 

\textbf{Ultra-Long GRBs} are events that last more than 10,000 seconds. They have been proposed to be caused by the collapse of a \href{https://en.wikipedia.org/wiki/Blue_supergiant}{Blue Supergiant} star, a \href{https://en.wikipedia.org/wiki/Tidal_disruption_event}{tidal disruption event} or a newborn \href{https://en.wikipedia.org/wiki/Magnetar}{magnetar}

\section{Astrosat and CZTI}
\subsection{Astrosat - India's first multiwavelength space telescope}
AstroSat is the first dedicated Indian astronomy mission aimed at studying celestial sources in X-ray, optical and UV spectral bands simultaneously. The payloads cover the energy bands of Ultraviolet (Near and Far), limited optical and X-ray regime (0.3 keV to 100keV). One of the unique features of AstroSat mission is that it enables the simultaneous multi-wavelength observations of various astronomical objects with a single satellite.

AstroSat with a lift-off mass of 1515 kg was launched on September 28, 2015 into a 650 km orbit inclined at an angle of 6 deg to the equator by PSLV-C30 from Satish Dhawan Space Centre, Sriharikota. The minimum useful life of the AstroSat mission is expected to be 5 years.


\begin{wrapfigure}{l}{0.4\textwidth}
    \centering
    \includegraphics[scale=0.8]{Pictures/astrosat_wireframe.png}
    \caption{Various Payloads on Astrosat (Source: \href{https://webapps.issdc.gov.in/astro_archive/archive/astrosat_images/astrosat_wireframe.png}{ISSDC})}
\end{wrapfigure}

The spacecraft control centre at Mission Operations Complex (MOX) of ISRO Telemetry, Tracking and Command Network (ISTRAC), Bengaluru manages the satellite during its entire mission life. The science data gathered by five payloads of AstroSat are telemetered to the ground station at MOX. The data is then processed, archived and distributed by Indian Space Science Data Centre (ISSDC) located at Bylalu, near Bengaluru.

\clearpage



\subsection{Cadmium-Zinc-Telluride Imager (CZTI)}


\begin{wrapfigure}[18]{r}{0.4\textwidth}
    \centering
    \includegraphics[scale=1]{Pictures/czti.jpg}
\caption{CZTI (Source: \href{http://astrosat.iucaa.in/czti/?q=home}{IUCAA})}
\end{wrapfigure}

It is a hard X-ray imaging instrument covering the energy band from 10 to 100 keV, has a detector area of 976 cm$^2$ constructed using CZT modules, and uses a Coded Aperture Mask (CAM) for imaging.
The CZTI carries a Cesium Iodide (Tl) based scintillator detector for Veto measurements. This is located just under the CZT detector modules. Further, there is a gap of about 8 cm between the base of the collimator slats and the detector plane, in order to accommodate a radioactive calibration source module in each quadrant. This source shines alpha-tagged 60 keV photons on the CZT detector in order to help calibrate the energy response.

Veto Detector - a detector (CsI) covers the large area of 256 cm2 and the light collection is done using two photomultipliers (PMT), viewed from sides. On registering an event, a signal from the detector is sent to a pre-amplifier. This signal is processed and sent to the FEB for further analysis. After amplification of the signal from pre-amplifier, the signal is sent to a comparator via stretcher along with LLD level signal. If LLD is triggered the pulse is digitized to an 8-bit output by ADC through control circuit. This output is used to differentiate Compton scattered events and hence the background in main detector can be reduced.

\begin{wrapfigure}[16]{l}{0.4\textwidth}
    \centering
    \includegraphics[scale=0.25]{Pictures/cztiassembly.png}
    \caption{CZTI Assembly (Source: \href{https://arxiv.org/pdf/2108.06746.pdf}{Image Calibration Paper})}
\end{wrapfigure}

The full CZTI detector is illuminated
only by the on-axis source. Off-axis sources illuminate
only a part of the detector depending on the position of
the source, this is called “partial coding”. The coded
mask for CZTI is designed with seven patterns based
on 255-element pseudo-noise Hadamard set Uniformly
Redundant Arrays (URA).  Each
pattern has 16×16 mask elements and used as a mask for an individual detector module. A random arrangement of these patterns into a 4 × 4 array results in the mask pattern for the first quadrant (quadrant A). The coded masks for the other quadrants (B, C, and D) were
obtained by rotating the mask pattern of quadrant A by
90°, 180° and 270° respectively.

A passive collimator wall of height 400 mm separates any two adjacent modules, restricting the view
of each detector module to the coded mask directly
above it. The collimator thus restricts the Field of View
(FOV) of CZTI to 4.6° × 4.6° FWHM at energies below
100 keV. For energies above 100 keV, the collimator
walls and the coded mask become progressively transparent, and allows the detection of Gamma-Ray Bursts
from all over the sky

\clearpage


\subsection{Coded Aperture Mask Imaging}

%\vspace{-1.1cm}

\begin{wrapfigure}[17]{r}{0.5\textwidth}
    \centering
    \includegraphics[scale=0.53]{Pictures/cam_working.png}
\caption{Working of a CAM (Source: \href{https://en.wikipedia.org/wiki/Coded_aperture}{Wikipedia})}
\end{wrapfigure}


Coded apertures or coded-aperture masks are grids, gratings, or other patterns of materials opaque to various wavelengths of electromagnetic radiation. The wavelengths are usually high-energy radiation such as X-rays and Gamma rays. By blocking radiation in a known pattern, a coded "shadow" is cast upon a plane. The properties of the original radiation sources can then be mathematically reconstructed from this shadow. Coded apertures are used in X- and Gamma ray imaging systems, because these high-energy rays cannot be focused with lenses or mirrors that work for visible light. 

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.69]{Pictures/CAM-czti.png}
    \caption{CZTI coded aperture mask for all four quadrants designed using 255 element pseudo-noise Hadamard
    set Uniformly Redundant Arrays. One extra closed element is added to each URA to obtain a square pattern. Here
    black areas represent closed mask elements and white areas represent open ones. (Source: \href{https://arxiv.org/pdf/2108.06746.pdf}{Image Calibration Paper})}
\end{figure}

\clearpage

\section{CZT Pipeline}

\subsection{How It Works}
The data received from the CZTI payload passes through a series of steps in a processing
pipeline. Three major data levels have been designated for long-term storage. These are:

\noindent\textbf{Level 0}

This is the raw data received from satellite telemetry, which is segregated by instrument,
along with auxiliary data. This data is archived internally and not distributed for public
use.

\noindent\textbf{Level 1}

This is reorganized raw data, written in FITS format for Astronomical use. All auxiliary
information necessary for further processing of this data are collated at this level and
packed along with the respective science data. This data is released via Astrosat data
archive, at first to the Principal Investigator (PI) of the corresponding observing proposal
and, after a specified initial lock in period, to anyone interested in the data.

\noindent\textbf{Level 2}

This data contains standard science products derived from Level 1 data. Level 2 data is
also in FITS format and is available for science use, with the same lock-in criteria and
release mechanism as the Level 1 data.

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.55]{Pictures/cztpipeline.png}
    \caption{Pipeline Work Flow (Source: \href{http://astrosat-ssc.iucaa.in/uploads/czti/CZTI_level2_software_userguide_V2.1.pdf}{CZT Software Userguide})}
\end{figure}

\subsection{Work Flow}

Data reduction for CZTI is performed in three stages. Each of these stages involves
execution of several tasks of the pipeline.

\begin{itemize}
    \item Stage 1: Generation of event file and calibration. In this stage event file is generated
    \item Stage 2: Selection of data and cleaning. In this stage events are selected based on Good Time Interval and noisy pixel events are removed from the data.
    \item Stage 3: Generation of science products. In this last stage,DPI, image, spectrum, light curve and response matrix are generated.
\end{itemize}

The pipeline tasks can either be executed individually or by using the cztpipeline
module which allows the user to run required stages of the pipeline tasks.


\subsection{Pipeline Installation}

I found Ubuntu 20.04 LTS to work best with the pipeline on WSL2. Other distros (including other versions of Ubuntu) gave various compilation errors.

To start off, update the system by running 
\begin{lstlisting}{language=bash}
    $ sudo apt update && sudo apt upgrade
\end{lstlisting}

After this, we must install some packages that are essential to ensuring the pipeline installs smoothly. Install them by running 
\begin{lstlisting}{language=bash}
    $ sudo apt install gcc g++ gfortran perl make
\end{lstlisting}


Now download the pipeline from \href{http://astrosat-ssc.iucaa.in/uploads/czti/czti_pipeline_20180308_V2.1.tar}{here} and the CALDB from \href{http://astrosat-ssc.iucaa.in/uploads/czti/caldb_goodfiles_as1_czti_20180308_V1.1.tar.gz}{here}. 

Untar these files, ideally in your home directory by running the following:
\begin{lstlisting}{language=bash}
    $ tar -xvf czti_pipeline_20180308_V2.1.tar
    $ tar -xvf caldb_goodfiles_as1_czti_20180308_V1.1.tar.gz
\end{lstlisting}


Now add the following to your \lstinline[language=bash]{.bashrc} file (by running \lstinline[language=bash]{$ sudo nano ~/.bashrc})
\begin{lstlisting}{language=bash}
    export as1czt=~/czti_pipeline/CZTI/czti/
    export PFILES="$PFILES:$as1czt/paramfiles"
    export PATH=$as1czt/bin:$as1czt/scripts:$PATH
    export GLOG_log_dir=$as1czt/log
    export CZTI_templates=$as1czt/templates
    export PERL5LIB="$as1czt/lib/":$PERL5LIB
    export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$as1czt/lib
    export PYTHONPATH="$PYTHONPATH:$as1czt/scripts"
    export CXXFLAGS="-fpermissive"
    ulimit -s 65532
    export CALDB=~/
\end{lstlisting}


Finally execute the following commands

\begin{lstlisting}{language=bash}
    $ source ~/.bashrc
    $ cd $as1czt
    $ cd ../
    $ ./InstallLibs
    $ cd $as1czt
    $ make
    $ cd scripts
    $ chmod +x cztpipeline
\end{lstlisting}



%----------------------------------------------------------------------------------------
%	CHAPTER 2
%----------------------------------------------------------------------------------------
\chapterimage{Pictures/BOAT.png}
\chapter{Playing With Data}

\section{Introduction}

\subsection{FITS Files}

FITS (Flexible Image Transport System) is a standard format for storing astronomical data. FITS is much more than an image format (such as JPG or GIF) and is primarily designed to store scientific data sets consisting of multi-dimensional arrays (1-D spectra, 2-D images or 3-D data cubes) and 2-dimensional tables containing rows and columns of information.

\noindent\textbf{Headers}

The FITS header is a block of text at the beginning of the file that contains information about the data contained within the file. The header is arranged in a series of keyword-value pairs, known as header cards, that each consist of a keyword, a value, and an optional comment. The keyword tells the type of information that the header card contains, the value is the actual value of the information, and the comment describes the information or how it was derived. The header is terminated by the keyword END.

\noindent\textbf{Data}

The data in a FITS file is stored in a series of N-dimensional arrays, where N is any number between 0 (empty) and 999. The data arrays are preceded by a series of header keywords that describe the size (NAXIS), location (NAXISn), data type (BITPIX), and other characteristics of the data arrays. The data arrays are stored in the file in the same order that they are listed in the header.

\subsection{Accessing Files via Astropy}

Astropy is a community Python library for Astronomy. It contains among other things:

\begin{itemize}
    \item A powerful N-dimensional array object
    \item Sophisticated (broadcasting) functions
    \item Tools for integrating Fortran code
    \item Useful linear algebra, Fourier transform, and random number capabilities
\end{itemize}

Opening a FITS file is as simple as:

\begin{lstlisting}[language=Python]
    from astropy.io import fits
    hdul = fits.open('file.fits')
    hdul.info()
\end{lstlisting}

This will print out the information about the file, including the number of HDUs in the file and the name and dimensions of each extension.

To obtain the data and header from the file, we can use:

\begin{lstlisting}[language=Python]
    data = hdul[0].data
    header = hdul[0].header
\end{lstlisting}


\subsection{Creating the Light Curve Files}

The light curve files are created by running the \lstinline[language=bash]{cztbindata} command in the terminal. The command takes in the following input files along with time bin size and produces the .lc and .pha (spectrum) file:

\begin{itemize}
    \item \lstinline[language=bash]{inevtfile} - The input evt file
    \item \lstinline[language=bash]{mkffile} - The input mkf file
    \item \lstinline[language=bash]{badpixfile} - The input badpix file
    \item \lstinline[language=bash]{livetimefile} - The input livetime file
\end{itemize}

Finally the .lc file can be opened using \lstinline[language=Python]{astropy.io.fits} and the required columns can be plotted. In our case we will be plotting the \lstinline[language=Python]{COUNTS} column against the \lstinline[language=Python]{TIME} column.

Here is a sample light curve file plotted for the duration of the GRB190928A:

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.65]{Pictures/sample_lc.png}
    \caption{Light Curve for GRB190928A}
\end{figure}

\subsection{Creating the Spectrum Files}

The process used in creating the light curve will automatically produce a .pha file which contains the spectrum of the GRB. We can plot the spectrum using \lstinline[language=Python]{astropy.io.fits} and \lstinline[language=Python]{matplotlib.pyplot}.

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.55]{Pictures/spectrum.png}
    \caption{Spectrum for GRB190928A}
\end{figure}

\subsection{Some Anomalies in the Data}

The above light curve was plotted around the time of the GRB, but if we plot the full light curve, we can see some anomalies in the data where the counts suddenly fall to zero.
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.3]{Pictures/anomaly.png}
    \caption{Anomaly in the Light Curve}\label{fig:anomaly}
\end{figure}

The region shaded in red is the region where the counts start rising then fall to 0. This is because there is a high influx of cosmic rays in a particular region in the South Atlantic Ocean. This region is known as the South Atlantic Anomaly (SAA). 

The SAA is a consequence of the fact that the Earth's inner Van Allen radiation belt comes closest to the Earth's surface at the south magnetic pole. This leads to an increased flux of energetic particles in this region and exposes orbiting satellites to higher than usual levels of radiation. 

The detectors on Astrosat are shut off when the satellite passes through the SAA, and hence the counts fall to 0. 

\section{Analysis of GRB190928A}

\subsection{Finding the GRB}

We notice two peaks in the light curve. The first peak is the \href{https://arxiv.org/pdf/1402.7022.pdf}{Prompt Emission}, and the second peak is the \href{https://astronomy.swin.edu.au/cosmos/G/Gamma+ray+burst+afterglow}{Afterglow}. We can find the GRB by looking at the \lstinline[language=Python]{COUNTS} column and finding the maximum value. We can then use the \lstinline[language=Python]{TIME} column to find the time at which the maximum value occurs. In this case, the GRB occurs at 2019-09-28 13:12:17 UTC. 

The duration of the GRB would be the time difference between the time at which the GRB starts and the time at which it ends. The start and end times are taken roughly before the prompt emission and after the afterglow respectively. In this case, the duration of the GRB is 132 seconds.

A thing to note is that \lstinline{cztbindata} produces .lc files for each quadrant of the CZT detectors (namely Quad 0, Quad 1, Quad 2 and Quad 3). We must plot all four quadrants to get a good idea of the GRB.

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.35]{Pictures/allquads.png}
    \caption{Light Curves for all four quadrants}
\end{figure}

The above plot shows the light curves for all four quadrants along with the peaks of the prompt emission and afterglow and markers for the start and end of the GRB.

\subsection{Filtering and Detrending}
%
%
%
% REFER THE FIGURE HERE 
% \ref{fig:anomaly}
%
From Figure \ref{fig:anomaly}, we can see that the "backgorund" data (the signal apart from the GRB) has a mean value somewhere around $100$, along with a lot of variation around that mean value. This variation is known as \textit{noise} and is caused by the inherent physics of the working of the CZTI detectors. There is also various "trends" present in the data due to the satellite observing various targets and the SAA region. These trends need to be "detrended"

We do this by taking a region of 1000 seconds around the GRB trigger time (500 seconds before and after the trigger time) and fitting a quadratic polynomial to the data. We then subtract this polynomial from the data to get the detrended data. To make the fitting easier, we can use the \lstinline[language=Python]{savgol_filter} function from the \lstinline[language=Python]{scipy.signal} module. 

The \lstinline[language=Python]{savgol_filter} function takes in the data, the window length and the polynomial order as input. The filter fits a polynomial of a given order to the datapoints in the window, then we fit a quadratic to the savgol fit and subtract the quadratic from the data to get the detrended data.

The above process is done for the data points \textit{outside} of a 3 sigma clip, so as to not detrend the GRB or include any outliers in the trend. 


\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{Pictures/trend.png}
    \caption{Trend in the Light Curve}
\end{figure}

We notice a slight "bowing" in the orange quadratic that was fit to the savgol fit. This is our trend in the data. We can now subtract this trend from the data to get the detrended data.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{Pictures/detrended.png}
    \caption{Detrended Light Curve}
\end{figure}

We can see that the detrended data has its mean counts close to 0 and is flatter than the raw light curve.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{Pictures/trend2.png}
    \caption{Trend in the lightcurve}
\end{figure}
Here we can see the trend more clearly in the data for GRB 160909A.
\newpage

\section{Different Bin Sizes}

Uptil now we have analysed the data using a bin size of $1$s. We can also analyse the data using different bin sizes to see how the results change. For the purposes of this analysis, we will be using bin sizes of $0.1$s, $1$s, $10$s.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{Pictures/allquads01s.png}
    \caption{Light Curves for bins of 0.1s}
    \label{fig:smallbins}
\end{figure}

Here we have the light curves of all four quadrants during the interval of the GRB. We can see that the smaller binsize causes the variations in the background to be more prominent. 

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{Pictures/allquads10s.png}
    \caption{Light Curves for bins of 10s}
\end{figure}

Here we can see that the larger binsize causes the variations in the background to be less prominent, as more of the noise gets smooothened (averaged) out.


%----------------------------------------------------------------------------------------
%	CHAPTER 3
%----------------------------------------------------------------------------------------
\chapterimage{lgm.png}
\chapter{Signal To Noise Ratio}

\section{Introduction}

The signal-to-noise ratio (SNR) is a measure used in science and engineering that compares the level of a desired signal to the level of background noise. SNR is defined as the ratio of signal power to the noise power, often expressed in decibels. A ratio higher than 1:1 (greater than 0 dB) indicates more signal than noise. While SNR is commonly quoted for electrical signals, it can be applied to any form of signal, in out case, we will be finding the SNR of a single in a timeseries. 

%
% REFER THE FIGURE HERE
% \ref{fig:smallbins}

Now, comparing the levels of the signal and noise are easier said than done. The signal is the GRB, and the noise is the background. The background is not constant, and varies a lot. This particular variation can be seen most clearly in Figure \ref{fig:smallbins}. GRB 190928A is a particularly bright GRB, so it is easy to see the GRB in the light curve. But what about fainter GRBs? How do we find the SNR of a faint GRB? We'll look at the various methods used to determine the SNR in the upcoming sections.


\subsection{Methodology}
There are a plethora of methods that can be used to determine the SNR of a GRB. There are methods that involve integrating the signal and noise separately and then dividing the two, there are methods that involve fitting a distribution to the noise and taking a certain percentile of the distribution as the noise and so on. Regardless of the methods, the crux of the matter is to find quantities that best describe the signal and the noise.

\newpage

\section{Signal}

Describing the signal is a fairly straightforward task as opposed to describing the noise.

The signal is the GRB, and the GRB is a peak in the light curve. So, we can describe the signal as the maximum value of the light curve textit{in the GRB window}. This is the simplest way of describing the signal, and is the method we will be using for the majority of this project and will be referred to as \textbf{$M_s$}.

Another method of describing the signal is to integrate the light curve over the duration of the GRB. This method will be taken as a baseline for the other methods.

\section{Noise}

Describing the noise is a much more difficult task than describing the signal. The noise is the background, and the background is not constant. The background varies a lot, and the variation is slightly different for each orbit of the satellite, as well as each quadrant of the CZT detectors.

\subsection{Method 1 - Raw Statistics of the Noise}

This method involves taking the raw statistics of the noise, namely the mean and standard deviation of the noise. The mean of the noise is taken as the mean of the light curve \textit{outside} of the GRB window. The standard deviation of the noise is taken as the standard deviation of the light curve \textit{outside} of the GRB window.

We can then take the noise as $\mu+\sigma$ and the signal as $M_s+\mu$. 

\begin{equation}
    \therefore \text{SNR} = \frac{M_s+\mu}{\mu+\sigma}
\end{equation}

\subsection{Method 2 - Fitting a Distribution to the Noise} \label{sec:method2}

This method involves fitting a distribution to the noise and then taking a certain sigma clip of the distribution as the noise. This method is more robust than the previous method as it takes into account the variation in the noise. Say for example, the noise is a Gaussian distribution, then we fit a Gaussian distribution by varying the mean ($\mu$) and standard deviation ($\sigma$) till we get the best fit. We then take the value of noise as $\mu+3\sigma$. 

There are quite a few different distributions that are of interest to us, namely the Gaussian, Poisson, Gamma, Weibull and Rayleigh distributions. We will be looking at each of these distributions and the troubles faced in fitting them in the upcoming sections.

\vspace{2cm}

\textit{\textbf{An important note:} When we fit the noise to some distrbution, according to the nature of the distribution, we get a value for the optimal mean and standard deviation that will fit our noise. Since the data has been detrended, our noise is centered around $0$, so our entire data must be shifted by the mean obtained by fitting, and our signal becomes \textbf{$M_s+\mu$.}}


\newpage

\subsection{Gaussian Distribution}

A Gaussian distribution is a continuous function representing the distribution of many random variables as a symmetrical bell-shaped graph. The Gaussian distribution is also known as the normal distribution. The equation for a Gaussian distribution is given by:

\begin{equation} \label{eq:gaussian}
    f(x) = \tfrac{1}{\sigma\sqrt{2\pi}}e^{-\tfrac{(x-\mu)^2}{2\sigma^2}}
\end{equation}

Where $\mu$ is the mean and $\sigma$ is the standard deviation of the distribution. The Gaussian is of some interest to us because the noise in the light curves follows a rough bell-shaped distribution. 

Fitting a Gaussian is pretty straight forward using the \lstinline[language=Python]{scipy.optimize.curve_fit} function, and defining a function that produces a purely Gaussian equation either by using the equation (\ref{eq:gaussian}) or the \lstinline[language=Python]{scipy.stats.norm.pdf} function. In either case, the function takes in the data as input and returns the mean and standard deviation of the distribution. 

We can then take the noise as $\mu+\sigma$ and the signal as $M_s+\mu$ (Recall the note at the end of Section \ref{sec:method2}).

\begin{equation}
    \therefore \text{SNR} = \frac{M_s+\mu}{\mu+\sigma}
\end{equation}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{Pictures/gaussian_fit.png}
    \caption{Fitting a Gaussian to the Noise (BinSize 0.1s) of Quadrant 0}
\end{figure}

It's clear from the above picture that our noise is \textit{not} Gaussian but a Gaussian is a good approximation of the noise.


\subsection{Poisson Distribution}

The Poisson distribution is a discrete probability distribution that expresses the probability of a given number of events occurring in a fixed interval of time or space if these events occur with a known constant mean rate and independently of the time since the last event. The Poisson distribution can also be used for the number of events in other specified intervals such as distance, area or volume. The Poisson distribution is defined as:

\begin{equation} \label{eq:Poisson}
    f(k; \lambda)=\frac{\lambda^k e^{-\lambda}}{k!}
\end{equation}
    
Where $k$ is the number of events, and $\lambda$ is the average number of events per interval. An interesting thing to note is that the mean and variance of the Poisson distribution are both equal to $\lambda$. The Poisson distribution is of interest to us because the noise in the light curves seems to have a skewed distribution, and the Poisson distribution, in general, approximates a skewed distribution well.

Fitting a Poisson distribution is a bit more complicated than fitting a Gaussian distribution. We use the \lstinline[language=Python]{scipy.optimize.curve_fit} function and defining a function that returns a Poisson distribution by using \lstinline[language=Python]{scipy.stats.poisson.pmf}. In this case we obtain only the mean of the distribution ($\lambda$). 

We can now take the noise as $\lambda+\sqrt{\lambda}$ and the signal as $M_s+\lambda$. 

\begin{equation}
    \therefore \text{SNR} = \frac{M_s+\lambda}{\lambda+\sqrt{\lambda}}
\end{equation}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{Pictures/poisson_fit.png}
    \caption{Fitting a Poisson Distribution to the Noise (BinSize 0.1s) of Quadrant 0}
\end{figure}

We can see that the Poisson distribution is a better fit to the noise than the Gaussian distribution.


\subsection{Gamma Distribution}

The Gamma distribution is a two-parameter family of continuous probability distributions. The exponential distribution, Erlang distribution, and chi-squared distribution are special cases of the Gamma distribution. There are two different parameterisations in common use:

\begin{itemize}
    \item With a shape parameter $k$ and a scale parameter $\theta$.
    \item With a shape parameter $\alpha = k$ and an inverse scale parameter $\beta = 1/\theta$, called a rate parameter.
\end{itemize}

In either case, the probability density function of the Gamma distribution is given by:

\begin{equation} \label{eq:Gamma}
    f(x; k, \theta) = \frac{x^{k-1}e^{-x/\theta}}{\theta^k\Gamma(k)}
\end{equation}
    
    Where $\Gamma(k)$ is the Gamma function, and the mean is given by $k\theta$ and variance is $k\theta^2$. The Gamma distribution is of interest to us because the noise in the light curves seems to have a skewed distribution, and the Gamma distribution can also approximate a skewed distribution well.

Fitting a Gamma distribution is a bit simpler than fitting a Poisson distribution. We use the \lstinline[language=Python]{scipy.stats.gamma.fit} function that can directly give us the shape and scale parameters of the distribution.

We can now take the noise as $k\theta + \sqrt{k\theta^2}$ and the signal as $M_s+k\theta$.

\begin{equation}
    \therefore \text{SNR} = \frac{M_s+k\theta}{k\theta + \sqrt{k\theta^2}}
\end{equation}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{Pictures/gamma_fit.png}
    \caption{Fitting a Gamma Distribution to the Noise (Binsize 0.1s) of Quadrant 0}
\end{figure}

We can see that the Gamma distribution is very close to the Poisson distribution in terms of the fit, maybe even better. 

\subsection{Skewnorm Distribution}

The skew normal distribution is a continuous probability distribution that generalises the normal distribution to allow for non-zero skewness. The probability density function of the skew normal distribution is given by:

\begin{equation} \label{eq:skewnorm}
    f(x; \omega, \alpha, \xi) = \dfrac{2}{\omega \sqrt{2 \pi}} e^{-\frac{(x-\xi)^2}{2\omega^2}} \int_{-\infty}^{\alpha \left(\frac{x-\xi}{\omega} \right)} \dfrac{1}{\sqrt{2 \pi}} e^{-\frac{t^2}{2}} dt
\end{equation}

Where $\omega$ is the scale parameter, $\alpha$ is the shape parameter and $\xi$ is the location parameter. The mean ($\mu$) of the distribution is given by $\xi + \omega \delta \sqrt{\frac{2}{\pi}}$, where $\delta = \frac{\alpha}{\sqrt{1+\alpha^2}}$ and the variance ($\sigma^2$) is given by $\omega^2 \left( 1 - \frac{2 \delta^2}{\pi} \right)$. The skew normal distribution is of interest to us because the noise in the light curves seems to have a skewed distribution, and the skew normal distribution can also approximate a skewed distribution well.

Fitting a skew normal distribution is similar to fitting a Gamma distribution. We use the \lstinline[language=Python]{scipy.stats.skewnorm.fit} function that can directly give us the shape, location and scale parameters of the distribution.

We can now take the noise as $\mu+\sigma$ and the signal as $M_s+\mu$.

\begin{equation}
    \therefore \text{SNR} = \frac{M_s+\mu}{\mu+\sigma}
\end{equation}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{Pictures/skewnorm_fit.png}
    \caption{Fitting a Skewnorm Distribution to the Noise (Binsize 0.1s) of Quadrant 0}
\end{figure}

We can see that the Skew Normal distribution is an equivalent or better fit to the noise than the Gamma distribution.

\subsection{Quantifying the Fits}

We can quantify the fits by calculating the \href{https://en.wikipedia.org/wiki/Root-mean-square_deviation}{Root Mean Square Deviation/Error} (RMSD or RMSE) of the fits. The RMSD is defined as:

\begin{equation}
    \text{RMSD} = \sqrt{\frac{\sum_{i=1}^{n} (f_i - o_i)^2}{n}}
\end{equation}
    
    Where $f_i$ is the value of the fitted distribution at the $i^{th}$ data point, and $o_i$ is the value of the original data at the $i^{th}$ data point. The RMSD is a measure of the differences between the values predicted by a model or an estimator and the values observed. The lower the RMSD, the better the fit.

Along with RMSD we can also calculate and compare various statistical properies of the fits such as the variance, skewness and kurtosis. These are referred to as the moments of the distribution. The moments of the original data and the fitted distribution can be compared to see how well the distribution fits the data.

\begin{table}[H]
    \centering
    \begin{tabular}{c|c|c|c|c}
        & RMSD & Variance & Skewness & Kurtosis \\
        \hline
        Gaussian & 14.35 & 855.78 & 0 & 0 \\
        \hline
        Poisson & 16.51 & 934.95 & 0.032 & 0.001 \\
        \hline
        Gamma & 13.12 & 937.23 & 0.311 & 0.145 \\
        \hline
        Skewnorm & 13.10 & 932.53 & 0.299 & 0.175 \\
        \hline
        Original Data & - & 1201.03 & 0.632 & 2.856 \\
    \end{tabular}
    \caption{Moments of the Original Data and the Fitted Distributions}
\end{table}

We can see that the Gamma and Skewnorm distributions have the lowest RMSD, and the moments of the Gamma and Skewnorm distributions are closest to the moments of the original data. However, upon fitting the distributions to the noise of the other quadrants as well as other light curves, we can see that the Skewnorm distribution is a better fit to the noise than the Gamma distribution.

\vfill

\textsl{Although we have fitted a variety of distributions, the true nature of the noise still remains a mystery. The noise is not a perfect fit to any of the distributions, thus, for SNR calculations, we will be using the \textbf{raw statistics} of the noise.}
\newpage 

\section{Energy Dependence of the SNR}

Every detection (count) made by the CZT detectors has an associated energy spectrum. \lstinline[language=Python]{cztbindata} produces a .pha file along with the .lc file. The .pha file contains the energy spectrum of the GRB. We can use this energy spectrum to find the energy distribution of all the counts in the orbit. We are also able to produce lightcurve files for different energy ranges.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{Pictures/spectogram.png}
    \caption{Spectogram of the region around GRB 190928A}
\end{figure}

\subsection{Energy Ranges}

We can see that the GRB is present in most of the energy range (20-200 keV) whereas the noise is predominantly present in the lower energy range (20-60 keV). These "noise" events with sufficiently high counts in the lower 20-60 keV range are known as cosmic rays. 

In order to distiguish between cosmic and real sources of counts, we can calculate the SNR of "outliers" in the lowest energy range and compare it with the SNR of the same outliers in higher energy ranges. If the SNR of the outliers in the higher energy ranges drops below a certain threshold, we can safely assume that the outliers in the lower energy range are cosmic rays and not real sources of counts. A real source of counts would have a SNR higher than our threshold in at least one of the higher energy ranges.
\newpage
So, how do we determine the right amount of energy ranges to use? We can plot the Signal, Noise and SNR for different energy ranges and see how they change with energy. For the purposes of this project, we tried using 2, 4, 6, 8 and 10 \textit{equal} energy ranges between 20-200 keV and 3 \textit{unequal} energy ranges (20-60, 60-100 and 100-200 keV respectively).

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Pictures/signalvsenergy.png}
        \caption{Signal vs Energy}
    \end{subfigure}
    \begin{subfigure}[b]{0.3\textwidth}  
        \centering 
        \includegraphics[width=\textwidth]{Pictures/noisevsenergy.png}
        \caption{Noise vs Energy}
    \end{subfigure}
    \begin{subfigure}[b]{0.3\textwidth}   
        \centering 
        \includegraphics[width=\textwidth]{Pictures/snrvsenergy.png}
        \caption{SNR vs Energy}
    \end{subfigure}
    \caption{Energy Dependence of the Signal, Noise and SNR}
\end{figure}


We can see that the Signal as well as Noise decrease with increase in energy, which is to be expected as the spectrum of a GRB or any source for that matter cannot be infinitely increasing with energy. However, the SNR increases with energy, which is a direct result of the cosmic rays being present predominantly in the lower energy range. Overall the noise drops faster than the signal with increase in energy, which is a good thing as it means that the SNR will increase with energy.

\subsection{The Optimal Energy Ranges}

Now comes the part of choosing the right amount of energy ranges. We can see that the SNR \textsl{in general} increases with increase in energy, reaches a maxima and then starts decreasing. This shows the spectrum of the GRB. Something like 2 - 4 energy bins are ideal for SNR calculations and outlier rejection as taking many energy bins leads to limited data in each bin, and taking too few energy bins leads to a lot of cosmic rays in the lower energy bins.

For the purposes of this project, we will be using 3 energy bins (20-60, 60-100 and 100-200 keV) as 20-60 keV will contain majority of the cosmic rays and random noise spikes, 60-100 keV will contain the GRB as well as some cosmic rays and 100-200 keV will predominantly contain the GRB.

\newpage

\section{Time Dependence of the SNR}
We have seen earlier how choosing different time bins can affect the light curve including the peak signal value and the noise. We can also see how the SNR changes by taking different time bins. 

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{Pictures/timevssnr.png}
    \caption{SNR vs Different time bins for GRB 170330A}
\end{figure}


From the above plot we can see that the SNR varies with time bins. In particular the SNR is highest for the binsize of 11 seconds. This is likely because the binsize of 11 seconds is the closest to the duration of the GRB (10 seconds), implying that the entire GRB is contained in a single bin. This is a best case result and is not likely to happen for most GRBs.

For example, we see a highly fluctuating SNR for the GRB 210709A and the peak SNR was found for the binsize of 9 seconds whereas the GRB duration was 14 seconds.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{Pictures/snrvstime.png}
    \caption{SNR vs Different time bins for GRB 210709A}
    \label{fig:timebins}
\end{figure}

%----------------------------------------------------------------------------------------
%	CHAPTER 4
%----------------------------------------------------------------------------------------
\chapterimage{algocover.png}
\chapter{The Algorithm}
Without the quantification and analysis of \textsl{each and every count} present in the light curve, we cannot attempt to provide a definitive result about the SNR or even the presence of a GRB. We proceed with this analysis by carrying out a series of steps to identify sources then classify them as real or cosmic purely by using their SNRs.

\section{Outliers}

Noise, as we know is predominantly present in the 20-60 keV energy range. So, we take our initial set of outliers as all counts which have an SNR greater than 1 in this energy range. For clarity we will refer to these outliers as \textbf{Type 1} outliers.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{Pictures/type1.png}
    \caption{Type 1 Outliers}
\end{figure}

\newpage

As we can clearly see, there are a lot of Type 1 outliers, and this is on purpose. We want to be able to identify as many sources as possible, in order to not miss out any faint GRBs. 

The next step is to classify these Type 1 outliers as real or cosmic based on their SNRs in the higher energy ranges. We can do this by calculating the SNR of each Type 1 outlier in the higher energy ranges and comparing it with a threshold SNR (typically chosen to be 3). 

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{Pictures/type2.png}
    \caption{SNR variation of Type 1 outliers in different energy ranges}
\end{figure}

If the SNR of the Type 1 outlier in either of the higher energy ranges is higher than the threshold SNR, we classify it as a possible real source, else we classify it as a cosmic ray or noise. We also reject sources whose SNR is less than 1 in the 20-200 keV range, even if they pass the above criteria. We will refer to these outliers as \textbf{Type 2} outliers.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{Pictures/type2_2.png}
    \caption{Type 2 and 3 Outliers}
    \label{fig:type2}
\end{figure}

In Figure \ref{fig:type2} the Type 2 outliers are marked in purple. We can see that they are a subset of Type 1 outliers. Now, we have to find potential GRBs out of these Type 2 outliers. To do so, we must compare \textsl{between} quadrants. If a Type 2 outlier is present at the \textsl{same} time stamp in \textbf{at least 2} quadrants, then that Type 2 outlier is classified as a \textbf{Type 3} outlier, or, in other words, a potential GRB. In the above figure, the green dots are the Type 3 outliers, they've been found in both Quadrant 0 and Quadrant 1, whereas the spikes without the green dots are Type 2 outliers that have been found in only one quadrant.

\newpage

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{Pictures/snroutliersenergy.png}
    \caption{Finding Poential GRBs in a haystack of outliers}
\end{figure}

From the above figures, we can see how well the algorithm is able to distinguish between all the outliers and possible GRB sources. Purple representing the Type 1 outliers, red representing the Type 2 outliers and green representing the Type 3 outliers. The Type 3 outliers are the only ones that are potential GRBs.

\section{Timebins}

The next step is to find the timebin for which the SNR of these Type 3 outliers is the highest. We can do this by iterating over different timebins. The criteria used to comapare each timebin is the average SNR of the Type 3 outliers across all quadrants in that timebin. The timebin with the highest average SNR is chosen as the timebin for which the results are to be reported. Figure \ref{fig:timebins} shows the SNR variation of the Type 3 outliers in different timebins.

\section{Results and Overview}

We run the above steps, starting from detrending, all the way to maximimizing the SNR over different timebins, for each GRB. The results are then stored in a .txt file as well a .pdf file. The .txt file contains the SNRs of the analysis for each GRB, whereas the .pdf file contains the raw and detrended light curves, SNR maximisation plots, outlier detection plots and the potential GRB marked in each light curve.

The python code for the algorithm along with results for other GRBs can be found at this project's GitHub \footnote[1]{Link to the repository: \href{https://github.com/ravioli1369/grbhunters}{https://github.com/ravioli1369/grbhunters}} repository. 

\newpage
A schematic of each step followed by the algorithm is shown below:

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{Pictures/algo.png}
    \caption{Schematic of the Algorithm}
\end{figure}

The algorithm was run on 10 GRBs, of which 9 were detected successfully and 1 was not detected. The results are shown below:

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{Pictures/results.png}
    \caption{Results of the Algorithm}
\end{figure}

A detailed report created by the script for GRB 1609009A is shown below, starting with the .txt file output followed by each page of the .pdf file output:

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{Pictures/txt.png}
    \caption{Text file output for GRB160909A}
\end{figure}

\includepdf[pages=-]{Pictures/output_for_GRB160909A.pdf}

\section{Blind Searches}
As a bonus, the algorithm can identify potential GRBs in a blind search by iterating through the timestamps of the light curve. The results of the blind search are shown below:

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{Pictures/blindsearch.png}
    \caption{Results of the Blind Search}
\end{figure}

We can see that the GRB was found at the correct timestamp and all outliers in other timestamps throughout the light curve were rejected.

%----------------------------------------------------------------------------------------
%	BIBLIOGRAPHY
%----------------------------------------------------------------------------------------

% \label{References}
% \lhead{\emph{References}}
% \chapterimage{erosita_allsky} % Chapter heading image

% \chapter{Results and Discussion}

% \chapterimage{orion}

% \chapter{References}


%----------------------------------------------------------------------------------------
%	INDEX
%----------------------------------------------------------------------------------------

% \phantomsection
% \setlength{\columnsep}{0.75cm} % Space between the 2 columns of the index
% \printindex % Output the index

\end{document}

